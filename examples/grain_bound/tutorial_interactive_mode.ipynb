{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import scipy\n",
    "import combo\n",
    "import os\n",
    "import urllib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download():\n",
    "    if not os.path.exists('data/s5-210.csv'):\n",
    "\n",
    "        if not os.path.exists('data'):\n",
    "            os.mkdir('data')\n",
    "        \n",
    "        with urllib.request.urlopen('http://www.tsudalab.org/files/s5-210.csv') as response, open('data/s5-210.csv', 'wb') as out_file:\n",
    "            out_file.write(response.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    download()\n",
    "    A =  np.asarray( np.loadtxt('data/s5-210.csv',skiprows=1,delimiter=',') )\n",
    "    X = A[:,0:3]\n",
    "    t  = -A[:,3]\n",
    "    return X, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the data  \n",
    "# X is the N x d dimensional matrix. Each row of X denotes the d-dimensional feature vector of search candidate. \n",
    "# t is the N-dimensional vector that represents the corresponding negative energy of search candidates. \n",
    "# ( It is of course unknown in practice. )\n",
    "X, t = load_data()\n",
    " \n",
    "# Normalize the mean and standard deviation along the each column of X to 0 and 1, respectively\n",
    "X = combo.misc.centering( X )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Declare the class for calling the simulator. \n",
    "# In this tutorial, we simply refer to the value of t. \n",
    "# If you want to apply combo to other problems, you have to customize this class. \n",
    "class simulator:\n",
    "    def __init__( self ):\n",
    "        _, self.t = load_data()\n",
    "    \n",
    "    def __call__( self, action ):\n",
    "        return self.t[action]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Design of policy\n",
    "\n",
    "# Declaring the policy by \n",
    "policy = combo.search.discrete.policy(test_X=X)\n",
    "# test_X is the set of candidates which is represented by numpy.array.\n",
    "# Each row vector represents the feature vector of the corresponding candidate\n",
    "\n",
    "# set the seed parameter \n",
    "policy.set_seed( 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interactive mode stars ... \n",
      " \n",
      "0001-th multiple probe search (random) \n",
      "\n",
      "current best f(x) = -0.980054 (best action = 4547) \n",
      "list of simulation results\n",
      "f(x)=-1.070602 (action = 15673)\n",
      "f(x)=-1.009056 (action = 9559)\n",
      "f(x)=-1.195844 (action = 16927)\n",
      "f(x)=-0.980054 (action = 4547)\n",
      "f(x)=-0.992820 (action = 2553)\n",
      "f(x)=-1.146676 (action = 13144)\n",
      "f(x)=-1.006255 (action = 10827)\n",
      "f(x)=-0.999862 (action = 1995)\n",
      "f(x)=-1.055445 (action = 10763)\n",
      "f(x)=-1.100970 (action = 16450)\n",
      "\n",
      "\n",
      "0002-th multiple probe search (random) \n",
      "\n",
      "current best f(x) = -0.980054 (best action = 4547) \n",
      "list of simulation results\n",
      "f(x)=-1.208666 (action = 13085)\n",
      "f(x)=-1.069404 (action = 15133)\n",
      "f(x)=-1.031642 (action = 1706)\n",
      "f(x)=-1.016702 (action = 2464)\n",
      "f(x)=-1.172569 (action = 17812)\n",
      "f(x)=-1.082219 (action = 16533)\n",
      "f(x)=-1.025272 (action = 1336)\n",
      "f(x)=-1.031761 (action = 10076)\n",
      "f(x)=-0.984972 (action = 8876)\n",
      "f(x)=-1.107730 (action = 15577)\n",
      "\n",
      "\n",
      "Start the initial hyper parameter searching ...\n",
      "Done\n",
      "\n",
      "Start the hyper parameter learning ...\n",
      "0-th epochmarginal likelihood -22.8397384798\n",
      "50-th epochmarginal likelihood -24.1776171399\n",
      "100-th epochmarginal likelihood -24.8310182858\n",
      "150-th epochmarginal likelihood -25.1541614865\n",
      "200-th epochmarginal likelihood -25.334465628\n",
      "250-th epochmarginal likelihood -25.4551550106\n",
      "300-th epochmarginal likelihood -25.5500914536\n",
      "350-th epochmarginal likelihood -25.6313012793\n",
      "400-th epochmarginal likelihood -25.7023874574\n",
      "450-th epochmarginal likelihood -25.7643476773\n",
      "500-th epochmarginal likelihood -25.8176978448\n",
      "Done\n",
      "\n",
      "0003-th multiple probe search (EI) \n",
      "\n",
      "current best f(x) = -0.965358 (best action = 7677) \n",
      "list of simulation results\n",
      "f(x)=-1.080313 (action = 8128)\n",
      "f(x)=-0.965358 (action = 7677)\n",
      "f(x)=-1.069888 (action = 6744)\n",
      "f(x)=-1.000745 (action = 5438)\n",
      "f(x)=-0.991714 (action = 5993)\n",
      "f(x)=-1.089947 (action = 11497)\n",
      "f(x)=-1.054229 (action = 1253)\n",
      "f(x)=-1.044660 (action = 4687)\n",
      "f(x)=-1.054012 (action = 5246)\n",
      "f(x)=-0.965678 (action = 5031)\n",
      "\n",
      "\n",
      "Start the initial hyper parameter searching ...\n",
      "Done\n",
      "\n",
      "Start the hyper parameter learning ...\n",
      "0-th epochmarginal likelihood -30.6042738797\n",
      "50-th epochmarginal likelihood -35.8323970997\n",
      "100-th epochmarginal likelihood -38.5632285433\n",
      "150-th epochmarginal likelihood -40.0195014495\n",
      "200-th epochmarginal likelihood -40.8402155845\n",
      "250-th epochmarginal likelihood -41.3330181381\n",
      "300-th epochmarginal likelihood -41.6536564484\n",
      "350-th epochmarginal likelihood -41.883012718\n",
      "400-th epochmarginal likelihood -42.0631217907\n",
      "450-th epochmarginal likelihood -42.2153702356\n",
      "500-th epochmarginal likelihood -42.3501791876\n",
      "Done\n",
      "\n",
      "0004-th multiple probe search (EI) \n",
      "\n",
      "current best f(x) = -0.963138 (best action = 7308) \n",
      "list of simulation results\n",
      "f(x)=-0.980979 (action = 4735)\n",
      "f(x)=-0.999359 (action = 7857)\n",
      "f(x)=-0.963138 (action = 7308)\n",
      "f(x)=-1.120441 (action = 2785)\n",
      "f(x)=-1.060749 (action = 5669)\n",
      "f(x)=-0.977188 (action = 10857)\n",
      "f(x)=-1.019301 (action = 11987)\n",
      "f(x)=-1.283628 (action = 12002)\n",
      "f(x)=-0.991675 (action = 5957)\n",
      "f(x)=-1.027484 (action = 5303)\n",
      "\n",
      "\n",
      "Start the initial hyper parameter searching ...\n",
      "Done\n",
      "\n",
      "Start the hyper parameter learning ...\n",
      "0-th epochmarginal likelihood -27.8101674631\n",
      "50-th epochmarginal likelihood -38.5151806586\n",
      "100-th epochmarginal likelihood -44.3860399514\n",
      "150-th epochmarginal likelihood -47.687639627\n",
      "200-th epochmarginal likelihood -49.6338245999\n",
      "250-th epochmarginal likelihood -50.8300879488\n",
      "300-th epochmarginal likelihood -51.5973262888\n",
      "350-th epochmarginal likelihood -52.1139626467\n",
      "400-th epochmarginal likelihood -52.4824699563\n",
      "450-th epochmarginal likelihood -52.7627945703\n",
      "500-th epochmarginal likelihood -52.9902029595\n",
      "Done\n",
      "\n",
      "0005-th multiple probe search (EI) \n",
      "\n",
      "current best f(x) = -0.959371 (best action = 6568) \n",
      "list of simulation results\n",
      "f(x)=-0.959371 (action = 6568)\n",
      "f(x)=-0.990530 (action = 5365)\n",
      "f(x)=-0.996815 (action = 8990)\n",
      "f(x)=-1.118381 (action = 2987)\n",
      "f(x)=-1.009032 (action = 1643)\n",
      "f(x)=-1.019266 (action = 11951)\n",
      "f(x)=-1.033086 (action = 8473)\n",
      "f(x)=-1.056302 (action = 11470)\n",
      "f(x)=-0.990425 (action = 333)\n",
      "f(x)=-1.124811 (action = 15021)\n",
      "\n",
      "\n",
      "Start the initial hyper parameter searching ...\n",
      "Done\n",
      "\n",
      "Start the hyper parameter learning ...\n",
      "0-th epochmarginal likelihood -10.6051046856\n",
      "50-th epochmarginal likelihood -32.3974384599\n",
      "100-th epochmarginal likelihood -45.3712800209\n",
      "150-th epochmarginal likelihood -53.1999146465\n",
      "200-th epochmarginal likelihood -58.0999678524\n",
      "250-th epochmarginal likelihood -61.26712643\n",
      "300-th epochmarginal likelihood -63.373135687\n",
      "350-th epochmarginal likelihood -64.8112173017\n",
      "400-th epochmarginal likelihood -65.8199219863\n",
      "450-th epochmarginal likelihood -66.5483225979\n",
      "500-th epochmarginal likelihood -67.0917875955\n",
      "Done\n",
      "\n",
      "0006-th multiple probe search (EI) \n",
      "\n",
      "current best f(x) = -0.959371 (best action = 6568) \n",
      "list of simulation results\n",
      "f(x)=-0.970388 (action = 6789)\n",
      "f(x)=-1.003224 (action = 3057)\n",
      "f(x)=-0.975826 (action = 6196)\n",
      "f(x)=-1.022587 (action = 6758)\n",
      "f(x)=-1.137064 (action = 3432)\n",
      "f(x)=-1.150921 (action = 8)\n",
      "f(x)=-2.497328 (action = 17945)\n",
      "f(x)=-2.497145 (action = 17981)\n",
      "f(x)=-0.983122 (action = 6695)\n",
      "f(x)=-1.189734 (action = 6011)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# How to use the interactive mode \n",
    "simulator = simulator()\n",
    "\n",
    "''' 1st step (random sampling) '''\n",
    "actions = policy.random_search(max_num_probes=1, num_search_each_probe=10, simulator=None)\n",
    "t  = simulator(actions)\n",
    "policy.write(actions, t)\n",
    "combo.search.utility.show_search_results(policy.history, 10)\n",
    "\n",
    "''' 2nd step (random sampling) '''\n",
    "actions = policy.random_search(max_num_probes=1, num_search_each_probe=10, simulator=None)\n",
    "t = simulator(actions)\n",
    "policy.write(actions, t)\n",
    "combo.search.utility.show_search_results(policy.history, 10)\n",
    "\n",
    "''' 3rd step (bayesian optimization) '''\n",
    "actions = policy.bayes_search(max_num_probes=1, num_search_each_probe=10, \n",
    "                                                      simulator=None, score='EI', interval=0,  num_rand_basis = 0)\n",
    "t = simulator(actions)   # experiment\n",
    "policy.write(actions, t) # record new observations\n",
    "combo.search.utility.show_search_results(policy.history, 10)  # describe search results\n",
    "\n",
    "predictor = policy.predictor\n",
    "training = policy.training\n",
    "\n",
    "actions = policy.bayes_search(max_num_probes=1, num_search_each_probe=10, \n",
    "                                                      predictor=predictor, training=training,\n",
    "                                                      simulator=None, score='EI', interval=0,  num_rand_basis = 0)\n",
    "t = simulator(actions)   # experiment\n",
    "policy.write(actions, t) # record new observations\n",
    "combo.search.utility.show_search_results(policy.history, 10)  # describe search results\n",
    "\n",
    "\n",
    "\n",
    "''' 4-th step (bayesian optimization) '''\n",
    "actions = policy.bayes_search(max_num_probes=1, num_search_each_probe=10, \n",
    "                                                      simulator=None, score='EI', interval=0,  num_rand_basis = 0)\n",
    "t = simulator(actions)   # experiment\n",
    "policy.write(actions, t) # record new observations\n",
    "combo.search.utility.show_search_results(policy.history, 10)  # describe search results\n",
    "\n",
    "predictor = policy.predictor\n",
    "training = policy.training\n",
    "\n",
    "actions = policy.bayes_search(max_num_probes=1, num_search_each_probe=10, \n",
    "                                                      predictor=predictor, training=training,\n",
    "                                                      simulator=None, score='EI', interval=0,  num_rand_basis = 0)\n",
    "t = simulator(actions)   # experiment\n",
    "policy.write(actions, t) # record new observations\n",
    "combo.search.utility.show_search_results(policy.history, 10)  # describe search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('predictor.dump', 'wb') as f:\n",
    "    pickle.dump(policy.predictor, f)\n",
    "policy.training.save('training.npz')\n",
    "policy.history.save('history.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start the initial hyper parameter searching ...\n",
      "Done\n",
      "\n",
      "Start the hyper parameter learning ...\n",
      "0-th epochmarginal likelihood 6.78070441562\n",
      "50-th epochmarginal likelihood -2.47887655713\n",
      "100-th epochmarginal likelihood -7.59893958954\n",
      "150-th epochmarginal likelihood -10.2862973812\n",
      "200-th epochmarginal likelihood -11.66234872\n",
      "250-th epochmarginal likelihood -12.3548082067\n",
      "300-th epochmarginal likelihood -12.7040042917\n",
      "350-th epochmarginal likelihood -12.8870117533\n",
      "400-th epochmarginal likelihood -12.9921850149\n",
      "450-th epochmarginal likelihood -13.0619789569\n",
      "500-th epochmarginal likelihood -13.1160665019\n",
      "Done\n",
      "\n",
      "0007-th multiple probe search (EI) \n",
      "\n",
      "current best f(x) = -0.959371 (best action = 6568) \n",
      "list of simulation results\n",
      "f(x)=-1.024627 (action = 11963)\n",
      "f(x)=-1.046521 (action = 15909)\n",
      "f(x)=-1.031994 (action = 9027)\n",
      "f(x)=-0.992651 (action = 462)\n",
      "f(x)=-0.985410 (action = 9139)\n",
      "f(x)=-0.994784 (action = 7214)\n",
      "f(x)=-0.970820 (action = 11969)\n",
      "f(x)=-1.013053 (action = 36)\n",
      "f(x)=-1.209990 (action = 21)\n",
      "f(x)=-1.067849 (action = 11811)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "''' delete policy'''\n",
    "del policy\n",
    "\n",
    "policy = combo.search.discrete.policy(test_X=X)\n",
    "policy.load('history.npz', 'training.npz', 'predictor.dump')\n",
    "\n",
    "''' 5-th probe (bayesian optimization) '''\n",
    "actions = policy.bayes_search(max_num_probes=1, num_search_each_probe=10, predictor=predictor, \n",
    "                                                      simulator=None, score='EI', interval=0,  num_rand_basis = 0)\n",
    "t = simulator(actions)   # experiment\n",
    "policy.write(actions, t) # record new observations\n",
    "combo.search.utility.show_search_results(policy.history, 10)  # describe search result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res=policy.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1112faa90>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEACAYAAABbMHZzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmYFOW1BvD3IDvIEhdEEVABUW4ERkVEgZYlIpsYveIW\nY1R44k2Uq4mKK6A3XmNiDHG7IS7XqxIXEBciyiAMRKIICmEREQMKyOKCgsAwwPS5f5xup6enq6uq\nq5rpot/f88wz09VV9X3dU33q1KmvqkVVQURExaVObXeAiIj2PwZ/IqIixOBPRFSEGPyJiIoQgz8R\nURFi8CciKkKBgr+ItBSRmSKySkTeFJHmDvNdLyLLRWSpiDwrIvWDtEtERMEEzfzHApilqscDmA3g\nlvQZRORIANcCKFHVkwDUBXBRwHaJiCiAoMH/XABPJf5+CsAIh/kOAtBEROoCaAxgY8B2iYgogKDB\n/3BV3QIAqroZwOHpM6jqRgD3A1gH4HMA36rqrIDtEhFRAHXdZhCRUgCtUicBUAC3Z5i9xr0iRKQF\n7AihHYBtAKaIyCWqOjmnHhMRUWCuwV9VBzo9JyJbRKSVqm4RkSMAfJFhtgEA1qjq1sQyLwHoBSBj\n8BcR3myIiMgnVRU/8wct+7wK4IrE3z8F8EqGedYB6CkiDUVEAPQHsDLbSlU1kj/jxo2r9T6w/7Xf\nD/Y/mj9R7n8uggb/3wIYKCKrYEH9XgAQkdYiMj0RyN8DMAXAYgD/hJWNJgVsl4iIAnAt+2SjVsoZ\nkGH6JgBDUx5PADAhSFtERBQeXuEbolgsVttdCIT9r13sf+2Kev/9klzrRfkiIlpofSIiKmQiAt3P\nJ3yJiCiCGPyJiIoQgz8RURFi8CciKkIM/kRERYjBn4ioCDH4ExEVIQZ/IqIixOBPRFSEGPyJiIoQ\ngz8RURFi8CciKkIM/kQFoLwcqKys7V5QMWHwJ0effw6sW1fbvaipogJ46y1g3z5/y+3aBdx6K/Dd\nd/npV65UgbPPBvr2BTZvru3eULEIFPxF5AIRWS4ilSJSkmW+QSLykYh8LCI3B2mT9p8bbwR++cva\n7kVNkyYBF1wAtGsH3H478Omn7sts22YB9v77gTlz8t5FX6ZMAbZvBwYMAHr0ABYurO0e+Xf77cAb\nb2SfR9V23MVOFZg8GbjpJiAer9WOBPreyOMBdAQwG0CJwzx1AHwCoB2AegCWAOicZZ3q11tvqT7y\niOqmTb4XJQe7dqk2b67arJnqli213ZsqlZWqHTqovv226vLlqmPGqB5yiOqPfqT6yiv2fLotW1S7\nd1e99lrVu+5SveEG/+3efbfq9derxuPBX0Oq8nLV9u1VZ8+2x9OmqR52mOpTT4XbTj6Vl6s2aaLa\nqpXqww9nnmfrVtWRI1Vbt1Zdv37/9W3HDtWdO/dfe25Wr1YdOFD1pJNUe/VS/eUvw9mmEnHTX/z2\nu0DGlQBzsgT/ngBmpDweC+DmLOvy/cKHD1ft2dOCVd++qg89pLpxo+/VHJC++EL1lFNUP/zQ33JT\np6r266d62WWqEyf6W7ayUvXbb/0t49Vrr9nrSf3A7Nql+vTTFuD/7d9Un31Wde9ee279etXjj1e9\n/XZbZt481ZNP9tfmN9+otmxp6x43zn+fy8udn7v3XtVzz60+bfly28GNGaO6alXVa6kN5eXun6W5\nc1VPPVX1k09UO3e2fu/bV/X8nDmqbdvazvfuu1VLSvZfQL7zTvvf50tlpb3uKVOsnaFDVY891gL8\n3Xfb9lZerrp7tz0+5BDV3/1Odc8e+4x07WoJSVCFGvzPBzAp5fFlAP6UZV2+X3j79vYhKS+37O+y\nyyxjXbzY96p0587qG26UVVSo9u6teuSRqhMm+Ft25EjV//kf1dJS+7Bms2uXBYB77lEdPFi1RQvL\nXnfvzr3vTvr3V33mmczPxeOqM2bYaz72WNX777dt43e/q5pn927LUv3snP77v1V/8hPVzZstKD/4\noPdlly1TPfjgqsw+1ebNFgw+/rjmc1u3WpvHHKPasKHqD3+oeuGFzpl1vowerdqnT/Z5JkxQvfFG\n+3vrVksahg5V/fpr1bFjLdt//XV7Ph631zVyZPhHUZlcf73qOefkZ93bt6ueeaZqmzaWgN55p+pL\nL6muXGlx6Fe/sp1ikyb2Hgwbpvrpp9XXsWmT6nHHqT76aLC+5CX4AygFsDTlZ1ni97CUeUIN/uPG\njfv+Z86cOVlf9LZtqo0b1wzYY8bYhzabvXstY7zpJtUhQ+yDVq+e6oABmcsHURKPq159tWWVs2er\nduvmfdmdO23n+cUX9r4edZQFsUy+/to27FNPtQ/a1KkW1Pr3V33uuXBeS9LSpbYjq6hwn3fePNUL\nLlB9/PGaz8ViVcHITXm5vb6lS+3xmjX2fvz1r96Wf+EF1RNPtJ3htGnVnxs92t4zNzt3qn7wge30\nDjtM9V//8tZ2UO+/b6Wcpk3t6MfJWWep/u1vVY/37FG96irbaQ0dWrNsWF6uetpplgnn2y9+Yf+/\nsO3YYUnG6NHusWL7dvv8OO3sPvnEtusXX/Te/pw5c6rFyULN/HsCeCPlseeyz/z5FkSymT/fAk+6\nadNUzz47+7LPPWclgd/8xuZftcoyw169VB94IPuyhW7iRCtTbN9uO7lDD1Vdu9bbsi++aDvApLFj\nqzK7dNdfr/rzn9ec/te/uv/v/LrqqnACxp13qt58s7d5//KXmpnj0qWqhx+u+uab7svfe6/qr3+t\numiR6hFHqD75ZPV1bN3qq+s6erTq73+ffZ7f/taOeK66yrbxL77w14aqBapevez1DxrkHJh277ad\nw7ZtNZdftMg54G3caBnz1Kn+++bH1VdblAvzvNXOnZZAXHlleEni4sW2Y583L7flazv4n+zw3EEp\nJ3zrJ074npBlXapq2V2XLqp16qh+9ZXzi370UdvI0339tR1u79njvOyVV6r+6U81p3/yiR2OL1/u\nvGxQyQ/HNddYPbmsLLx1z5xpgWbNmqppP/uZ6h//6G35Cy9UnTSp6vGKFZY9pR9drV5t79PmzTXX\nsXu37XDCylK/+MLKSbkEsnRvvWXniNxUVqp26mQ163R//7t9WD/5JPs6Ro+2wQiqVg5o29YSiwED\n/JWPkmbMsKDsJB630tRzz9m2PXy4nQvr1s3KM279TXrmGTs3sm+fJRJXXpl5vnnzMidfXixcaNvI\nkiW5Le/F5ZdblJs5M/t8XktQu3bZ/+4nPwm/PPzww9bfXOz34A9gBID1AMoBbEqe2AXQGsD0lPkG\nAVgFYDWAsS7rVNWq+nEspvrGG84v+pprnINa166q//hH5uficcs8Vq3K/PykSXYC0UuJwY9vv7UP\nfdeuqu3a2cme0aNVb7nF/7ruv9+C8lln2aiBRx9VffllyyjTdyavvmonw93s2GElny+/rD79lFNq\n/h/OP9+Ompz853+q3nqrp5fi6u67M+/kc7Fzp9Vhd+zIPt+0aao9ejgHhosvdh+VM2BA9ffts89s\nh9K5c/bExElFhe0EnUa2LVig2rFj9T7v3Wujo667zraNnj1tUITTjvS776y0NX++PV692razTO/D\nXXc5HxV68fDDVgvPl5Ej7TXfd5/zPBUVVt76j/+oud2nKi+3o6CLL87PecH337ej9VzUWuYf5g+A\n7zPvtWttw8p2qH/mmZlPpqla8LnnnszPrVhhwdfpgx2PW70yrOClaoe6J5yg+uMf24nU5CFjaWn2\nbC6TJUssa1q40ILL/fdbdtarV+aAtGtX5qCe7oUXbKRCugcfVL3kkqrHf/+76tFH23qdLF9uQSPo\naJWKiup19zCccYa9707icQuSU6Y4zzNunPtIkuOOq5lgbN1qO4FcXXyxnYzPZMyY7COS9uyx8x2X\nXGI7kZtvtmCf6pZbLLNN1aFD5gEU/fqpTp/uq/vVfPutbZf5Gh123nm2c0nddtO9+66Vf6+91j5T\n999fPelbvNje18MOs8Ek+Rp9tXu3aqNGuY2EOmCC/8CBVSM0nn/eDl0zicezB7SXX7bx35k88IDq\nqFGZn0vavNnKJ8kMKIgNGyzjy7Qj27HDWyaaVFFh44ST9WOvzj9f9Yknss9zwQVW50335ZdWPti2\nzXZaPXrYyXI3p59uIx/cfPed7cTuvFP1scdsBExyx/zMM+GfP7jlluyBe948C3jZMrxnnrESmZO9\ne1Xr1w9/1NOLL2bervfts+3V6Wg23aZNFuSPPtrWGY9XlfI+/7z6vNddV/MoL1nvDxq4hw/P33UN\ngwfbZ+7EE53n+f3vLetXtdLckCH2vx83zo7Q27ZVveMO7yWzILp3t52RXwdM8O/ateqQeM0aOxOe\nyaefOj+nmr3uf8452bO6pGnTbNjg9u3u8zr57DPLAO+913meXr2yZ6KpbrvNshm/Q+Weftp5R6pq\nAbhZM+dzLCNG2OiZyZOtDOTlZNcTT9gRVCbLltlIq9NOs51fnz52cvnSS60kd8QRFlw7dbKyVZje\neMNGazgZOtQ5u05asMA+rE7WrrXAGrbvvrPtOn0EzsyZ9n/xa+5cKzcMHGiZ/G9/W3OeGTPsKDvV\nvHm5tZfu2Wct4ObDgAF2ZNKokfNR6ogRtk2nevNNGyk0a9b+Hfl31VVV54j8OGCC/4IFVS8qHs+c\niahaQHAb0dOtW826f3m5fXi8jrS4+mor1eSyEaxda0NI//CH7PO5ZaJJCxZYDTOXq5m3brXX7XSE\n8dxz2d/Pl16yTL5dOwsYXuzYYSe0N2yoPr201A6j77jDTqimfzDjcXvvnnrK5gn7A7h9u+1wMl2A\ntXSp7XiyXZylau9n06bOO+G33vJ2niUXw4bVvN7hiivctzMne/bYsgMGZD5S2bWr5mfmrrtsJFNQ\n27db0uF35JMXvXvb+a+uXa1Emi4et+1w3brw287FI49YvPErl+BfkDd269Gj6m8R4NRTM9/vZNky\n4KSTsq8rFgPKyqpPmz8f6NIFaNnSW38eegj48ku7KZgfGzbYzbpuuAG4/nr3fs6dm32e8nLgpz8F\n/vQn4Igj/PUFsNd72mnAm29mfv6FF4ALL3RefsgQYNUqoHt3oE8fb202aWLrfPLJqmlTpwKXXGL3\ntLnrLnvtjRpVX04EaN8euPxym6dOyFvqwQfbNrBgQfXp8ThwzTV2r5qGDbOvo2VLm8fpZmxr1gDH\nHhtOf9Oddx4wbVrV4/Jy4OWXgZEjc1tfvXq2jZaWAg0a1Hy+USOgd297PqmszP53QR18MNC/v/U/\nbHv22Ovp2hVYsqTm86tX22s7+ujw285FSQnwwQfZ5/nZz4CvvgreVkEG/3ROwX/pUm/BP/1GXjNn\nAj/6kff2GzQAXnrJglVqEHPz9NPAoEHebo7Wq5f908vLnee54w7ghz/M/QMOACNGZP6Q7dgBzJpl\nzzupX99e/8SJ/tocNQp4/HELrI89Blx7re2AvO5A8qVPn5o73Ecftd/XXONtHR07WgDJZM0a4Jhj\ncu9fNsOGWSBObi9/+xtw8snAkUfmpz0AGDwYeP11+7uiAnjvPeDMM8NZ94UXWvIRtooK2267dcsc\n/N9+GzjjjPDbzdVJJwErVzrfAG/dOmD6dOAHPwje1gEf/Pv0Ad55xzKApJkz7Q6Pfhx6qL3pY8fW\nPJJw8uabwPDh3uZt2tQC+7vvZn5+6VLg2WeBRx7xtj4n555rgWLv3qppn39uQX/IEPeNavhwoG1b\nf22WlAAtWli2/5vfWMDt3t1/38PWt2/14L9uHTBunO2gvB5pdOrkHPzXrs1f5n/ooRbsZ860x5Mn\n2/ubT+ecY3fujMct8HfuDDRvHs66hw4F/vEP4Ouvw1lfUjLz79YN+Oc/az7/9tvh7cDC0KgRcNxx\nwIoVmZ8vLbW7v4ZxJByZ4L9okd0KNWn3bvtwde6cfdmWLS07W7TIHm/ZYrcATi0tedW5s33IRo4E\nPv44+7zffQe8/76/w+L0YJRq4kTguuvsQx9Emza2cc2bZ4+nTbPg3Lcv8H//F2zdTkTs6GfFCvuw\ndeyYn3b8OvNMC2J79ti29fOfW+nDbZtK1bGj87aQz7IPUFX6+eYb+36DH/84f20B9lqaNwcWLw6v\n5JPUtKkdjYdd+klm/l27WvBPv4VyoQV/IHvpp7QUGDgwnHYiEfyPOAJo3Ng+TEkrVwIdOtg/1k1q\n3b+0FDjrLKBu3dz60r8/8F//ZZnKzp3O882ZYzuYJk28r9sp+H/1lZWdRo3y399MzjvPjiJGjQJ+\n/WvglVespJTre+LFlVfa0ctRR+WvDb9atKhKDJ591o6AbrrJ3zrcyj75DP4jRtjR6PPP23bZokX+\n2koaPBiYMSP84A9Y6ef558NdZzLz/8EPLBFcu7bquS++sJ8uXcJtMyin4B+PW2m2qII/AJxySlX2\nDngr+SSlBv9cSj7pRo2y7DlblvLmm/7bOeMMK2/t3l19+mOP2Qc9aNafNGKE1e737rU6aM+e4aw3\nGxH7KTR9+9q5nF/9ys5L1Kvnb3mnss/27fbNYYcfHk4/Mzn6aNu53HEHcOml+Wsn1Tnn2NFGmPX+\npCFD7AT8l1+Gt85k5g/UPOk7f76dazvooPDaC8PJJ2cO/osXA4cdFt7J6cgE//S6/9KlViP3ondv\nq/tXVPg/2evk8suBZ55xfj6X4N+sGXDiifbBStq3z+r8116bWz8zOeEEC1j/+7820qKY9ekDPPCA\n/T9POcX/8h06AJ98UrOckKz353uHd955lt0OHpzfdpL69AE++ijcen9S48ZVO5ewJDN/oGbdvxBL\nPoDtpJYtq/k1pWHFrqTIBn8vwzyTknX/xx+3YBfGCIxzz7WTs1u21HzuX/+ykpDX/qVKL/288oqd\nYC1x/JLM3HToEO76oioWA/7934EJE3JbvmlTKyls2FB9ej5H+qS66irgiSdqDpXNl4YNgX79bDvN\nh7BLP6mZf/qIn0Ib6ZN08MGW3X/0UfXpYdb7gQgF/1NOscOeykp77KfsA1id/+67w9tzNm5sw+2e\ne67mc8k9dC5ZX/p1CQ8+GG7WT9W1bGlDDBs3zn0dmer++Rzpk+rww4Hzz89/O6n++Ec7V5QP55xj\nAyUyJVW5SM/8k8F/505g+XJLKgtRSYm9D0k7d1ryG+Z5lsgE/5YtgVatbG+4ZYv9U/2cPIzF7GKc\noPX+VJddZicK0+VS8klKHYGydKkFlXyP4qBgMo34yffJ3tp03HG5XWToRaNGdiFjSQlw441Wpkkd\n5edHZaWV45I1/fbtgW3bbDjpe+9Z8hhkp59P6Sd9582zaU2bhtdGZII/UFX6WbbM6v1+MuvevYFD\nDgl3z9mvH7B+vV31mrR3r2XuAwbkts7mzYHjj7fX+eCDNvzQ70lI2r8ynfQ9kIN/vk2caCWO+vWt\nvHrSScAf/uB/J1BRYVl/Mk7UqVM15HP+/MKs9yelB/+w6/1AhIO/33p6ixbApk12UjUsdesCF19c\nPft/5x3LjIKM8ujbt+qK4tGjg/eT8itT2YfBP5gTT7QLAtessQEP99xj59L82LOn5lDwZPAv1JO9\nSSUlVqJKDiQIu94PRDT4+633J+Ujg770Ugv+yawkSMknqW9fy36GDbNSFxW29LJPPG4XErZvX1s9\nOnDUqWNH7a1a1RwC7SaZ+afq1s1q6e+8Y8M8C1WLFpZArl5t159s2mRDQMMUKPiLyAUislxEKkUk\n43gUEWkjIrNFZIWILBOR63Jtr3t3O0mzaFFuwT8fSkosu0jeliGM4N+7t+1MeKI3Go47Dvjss6qh\neRs32jmqQq0nR1GDBs73u3GSKfPv1s1G0LVubWPmC1my9DNrlpWYw74eIeg1ncsAnAfgz1nm2Qfg\nBlVdIiJNAbwvIjNV9aMsy2TUpIl90JYvL5yr8kTsxO8zz9jwydWrgdNPD7bOli1t7Pj+GCpIwTVs\naCdAP/vMts/9NdKnmDRoEE7m36WL3QyvkEs+Scngv3Fj+CUfIGDmr6qrVHU1AMdTr6q6WVWXJP7e\nAWAlgJwv8j/1VPuAhXnWO6hLLrHhgq+/bieUvdxywg0Df7R06lRV+mG9P3wNG4aT+TdsaBc5RiX4\nL1oU7i0dUu3Xmr+ItAfQDcCC7HM6O/30wrgjZKpjjrEROnfeGe5QUoqO1JO+DP7hy6XskynzB4A/\n/3n/XxuRi+7dbYhns2b5SQZdyz4iUgog9bSjAFAAt6nqa14bSpR8pgAYkzgCcDR+/Pjv/47FYoil\njM+84opg97PPl8sus3vAM/gXp/Tgn+tQX8osl7JP6gVeqQr5RG+qww+372fINMSzrKwMZV7vLe/A\nNfirauADDhGpCwv8T6vqK27zpwb/dPXqFea495Ej7QK0446r7Z5QbejUye52Cey/WzsUk1zKPqm3\ndoiqYcMyX+SZnhRPyOH+JGHexDfbJVdPAPhQVX1+B1R0tGxpl71TcUrN/HnCN3y5jvbJlPlHSdAv\nb8om6FDPESKyHkBPANNFZEZiemsRmZ74+wwAlwLoJyKLReQDERkUtONEhaR9exuV8e23wNat+f06\nxWKU62ifqGf++RQo81fVlwHUuKu9qm4CMDTx93wABXbHbKJw1atnd1996y3bEYT9hfPFLtfRPlHP\n/POJmyhRSDp2tIv8WPIJX66jfZj5O2PwJwoJg3/+hDnahwyDP1FIOnUC1q3jSJ98KNbRPvnE4E8U\nko4d7Tcz//AV62iffGLwJwpJp072m8E/fBztEz4Gf6KQHH203S2SwT98HO0TvjAv8iIqanXq2Be5\nc5hn+DjaJ3zcTIlCxMCfHxztEz5uqkRU8DjaJ3wM/kRU8DjaJ3wM/kRU8DjaJ3wM/kRU8DjaJ3wM\n/kRU8DjaJ3wM/kRU8ML6AneqwuBPRAUvrC9wpyoM/kRU8ML8AncyQb/J6wIRWS4ilSJS4jJvncS3\neL0apE0iKj65XuTFzN9Z0Mx/GYDzAMz1MO8YAB8GbI+IilCuF3kx83cWKPir6ipVXY3sX94OEWkD\nYDCAx4K0R0TFKdeLvJj5O9tfNf8HANwIQPdTe0R0AKlf34J5PO59GWb+2bne1VNESgG0Sp0EC+K3\nqeprHpYfAmCLqi4RkRhcjhIAYPz48d//HYvFEIvF3BYhogNYnTpVO4CGDb0tcyBn/mVlZSgrKwu0\nDlENnoyLyBwAv1LVDzI8dw+AywDsA9AIwMEAXlLVyx3WpWH0iYgOLM2aAevXA82be5u/XTtg7lyg\nffu8dqsgiAhU1TWxThVm2Sdjw6p6q6q2VdVjAVwEYLZT4CcicuJ3xA9v75Bd0KGeI0RkPYCeAKaL\nyIzE9NYiMj2MDhIRAf5H/PD2DtmFUvYJE8s+RJRJhw7AjBlAx47e5m/aFNi82X4f6Gq77ENElDd+\nyz7M/LNj8CeiSPBT9onHgX37gHr18tunKGPwJ6JI8HOhV3KYp/gqhBQXBn8iigQ/ZR+O9HHH4E9E\nkeCn7MN6vzsGfyKKBL9lH2b+2TH4E1Ek+Cn7MPN3x+BPRJHgp+zDzN8dgz8RRYKfsg8zf3cM/kQU\nCRztEy4GfyKKBI72CReDPxFFgt+yDzP/7Bj8iSgS/JZ9mPlnx+BPRJHgt+zDzD87Bn8iioRc7u1D\nzoJ+mcsFIrJcRCpFpCTLfM1F5EURWSkiK0TktCDtElHx8XuRFzP/7IJm/ssAnAdgrst8EwG8rqon\nAOgKYGXAdomoyPi9yIuZf3Z1gyysqqsAQMT5xqki0gxAb1W9IrHMPgDbg7RLRMWHmX+49kfN/xgA\nX4nIkyLygYhMEpFG+6FdIjqAsOYfLtfgLyKlIrI05WdZ4vcwj23UBVAC4GFVLQGwC8DYAH0moiLE\n0T7hci37qOrAgG1sALBeVRclHk8BcHO2BcaPH//937FYDLFYLGAXiCjqOM6/SllZGcrKygKtI1DN\nP03Gur+qbhGR9SLSSVU/BtAfwIfZVpQa/ImIAF7hmyo9KZ4wYYLvdQQd6jlCRNYD6AlguojMSExv\nLSLTU2a9DsCzIrIENtrnniDtElHx4S2dwxV0tM/LAF7OMH0TgKEpj/8J4NQgbRFRceOXuYSLV/gS\nUSTwaxzDxeBPRJHAWzqHi8GfiCKBX+YSLgZ/IooEfo1juBj8iSgSONonXAz+RBQJ9esDe/cC8bj7\nvMz83TH4E1EkiFhA95L9M/N3x+BPRJHhtfTDzN8dgz8RRYbXET/M/N0x+BNRZHgd8cPM3x2DPxFF\nhteyDzN/dwz+RBQZXss+zPzdMfgTUWT4Kfsw88+OwZ+IIsNP2YeZf3YM/kQUGX7KPsz8s2PwJ6LI\n8Fr2YebvLug3eV0gIstFpFJESrLMd31ivqUi8qyI8N9CRL55KfuoMvh7ETTzXwbgPABznWYQkSMB\nXAugRFVPgn172EUB2yWiIuSl7LN3L1C3LlCHdY2sgn6N4yoAEJGMX96e4iAATUQkDqAxgI1B2iWi\n4uSl7MN6vzd53zeq6kYA9wNYB+BzAN+q6qx8t0tEBx4vZR+WfLxxDf4iUpqo1Sd/liV+D/PSgIi0\nAHAugHYAjgTQVEQuCdZtIipGXso+zPy9cS37qOrAgG0MALBGVbcCgIi8BKAXgMlOC4wfP/77v2Ox\nGGKxWMAuENGBwEvZpxgy/7KyMpSVlQVaR6Cafxqnuv86AD1FpCGACgD9ASzMtqLU4E9ElOSl7FMM\nmX96UjxhwgTf6wg61HOEiKwH0BPAdBGZkZjeWkSmA4CqvgdgCoDFAP4J20lMCtIuERUnL2WfYsj8\nwxB0tM/LAF7OMH0TgKEpjycA8L9rIiJK0aAB8M032ecphsw/DBwJS0SR4XW0D4O/OwZ/IooMr6N9\nWPZxx+BPRJHhdbQPM393DP5EFBleR/sw83fH4E9EkeF1tA8zf3cM/kQUGV7v7cPM3x2DPxFFBkf7\nhIfBn4gig6N9wsPgT0SRwdE+4WHwJ6LI4Gif8DD4E1FkcLRPeBj8iSgyONonPAz+RBQZvKVzeBj8\niSgyeEvn8DD4E1Fk8Avcw8PgT0SRUb8+sG8fUFnpPA8zf2+CfpPXfSKyUkSWiMhUEWnmMN8gEflI\nRD4WkZvVmCR4AAALVklEQVSDtElExUvEPftn5u9N0Mx/JoAuqtoNwGoAt6TPICJ1ADwE4GwAXQBc\nLCKdA7ZLREXK7aQvM39vAgV/VZ2lqvHEw3cBtMkwWw8Aq1X1M1XdC+A5AOcGaZeIihcz/3CEWfO/\nEsCMDNOPArA+5fGGxDQiIt/cRvww8/fG9QvcRaQUQKvUSQAUwG2q+lpintsA7FXVyWF0avz48d//\nHYvFEIvFwlgtER0A3Mo+xZD5l5WVoaysLNA6XIO/qg7M9ryIXAFgMIB+DrN8DqBtyuM2iWmOUoM/\nEVEqt7JPMWT+6UnxhAkTfK8j6GifQQBuBDBcVZ3+HQsBdBCRdiJSH8BFAF4N0i4RFS+3sk8xZP5h\nCFrzfxBAUwClIvKBiDwCACLSWkSmA4CqVgL4JWxk0AoAz6nqyoDtElGR4mifcLiWfbJR1Y4O0zcB\nGJry+A0Axwdpi4gI4GifsPAKXyKKFC+jfRj83TH4E1GkeBntw7KPOwZ/IooUL6N9mPm7Y/Anokjx\nMtqHmb87Bn8iihQvo32Y+btj8CeiSMlW9lFl5u8Vgz8RRUq2sk9lJVCnDnDQQfu3T1HE4E9EkZKt\n7MOs3zsGfyKKlGxlH9b7vWPwJ6JIyVb2YebvHYM/EUWKW9mHmb83DP5EFCluZR9m/t4w+BNRpLiV\nfZj5e8PgT0SRkq3sw8zfOwZ/IoqUbGUfZv7eMfgTUaRkK/sw8/cu6Nc43iciK0VkiYhMFZFmGeZp\nIyKzRWSFiCwTkeuCtElExY2jfcIRNPOfCaCLqnYDsBrALRnm2QfgBlXtAuB0AL8Qkc4B2yWiIsXR\nPuEIFPxVdZaqxhMP3wXQJsM8m1V1SeLvHQBWAjgqSLtEVLw42iccYdb8rwQwI9sMItIeQDcAC0Js\nl4iKCEf7hMP1C9xFpBRAq9RJABTAbar6WmKe2wDsVdXJWdbTFMAUAGMSRwCOxo8f//3fsVgMsVjM\nrZtEVCQ42gcoKytDWVlZoHWIqgZbgcgVAEYB6KeqGf8lIlIXwHQAM1R1osv6NGifiOjAtWED0KMH\nsHFjzecmTQIWLgT+8pf936/aJCJQVfGzjGvm79LgIAA3AujjFPgTngDwoVvgJyJyw9E+4Qha838Q\nQFMApSLygYg8AgAi0lpEpif+PgPApQD6icjixHyDArZLREWKo33CESjzV9WODtM3ARia+Hs+AH6v\nDhGFgqN9wsErfIkoUurVA+Jx+8rGdPwyF+8Y/IkoUkScSz/8MhfvGPyJKHKcSj/M/L1j8CeiyHEa\n8cPM3zsGfyKKHKeyDzN/7xj8iShynMo+zPy9Y/AnoshxKvsw8/eOwZ+IIoejfYJj8CeiyOFon+AY\n/IkocjjaJzgGfyKKnGxlH2b+3jD4E1HkZCv7MPP3hsGfiCInW9mHmb83DP5EFDnZLvJi5u8Ngz8R\nRU62i7yY+XvD4E9EkZPtIi9m/t4ECv4icp+IrBSRJSIyVUSaZZm3TuJbvF4N0iYREUf7BBc0858J\noIuqdgOwGsAtWeYdA+DDgO0REXG0TwgCBX9VnaWq8cTDdwG0yTSfiLQBMBjAY0HaIyICONonDGHW\n/K8EMMPhuQcA3AhAQ2yPiIoUR/sE5/oF7iJSCqBV6iRYEL9NVV9LzHMbgL2qOjnD8kMAbFHVJSIS\nSyyf1fjx47//OxaLIRaLuS1CREUkU9mnstK+27eua1SLvrKyMpSVlQVah6gGS8ZF5AoAowD0U9Ua\n+2IRuQfAZQD2AWgE4GAAL6nq5Q7r06B9IqID22OPAe+8Azz+eNW08nKgZcvM5wIOdCICVXVNrFMF\nHe0zCFbOGZ4p8AOAqt6qqm1V9VgAFwGY7RT4iYi8yFT2Yb3fn6A1/wcBNAVQmhjG+QgAiEhrEZke\nuHdERBlkKvuw3u9PoOqYqnZ0mL4JwNAM0+cCmBukTSKiTKN9mPn7wyt8iShyMpV9mPn7w+BPRJGT\nqezDzN8fBn8iipxMZR9+haM/DP5EFDlOo31Y9vGOwZ+IIsdptA8zf+8Y/IkocpxG+zDz964ILoQm\nogNNgwbA1q3AAw8AqvazciUzfz8Y/Ikoclq1Aq65Bvj0U6BOHUAEaN4cGFrj6iJyEvjePmHjvX2I\niPzZ7/f2ISKiaGLwJyIqQgz+RERFiMGfiKgIMfgTERUhBn8ioiIU9Ju87hORlSKyRESmikgzh/ma\ni8iLiXlXiMhpQdolIqJggmb+MwF0UdVuAFYDuMVhvokAXlfVEwB0BbAyYLsFKegXKtc29r92sf+1\nK+r99ytQ8FfVWaoaTzx8F0Cb9HkSRwO9VfXJxDL7VHV7kHYLVdQ3Hva/drH/tSvq/fcrzJr/lQBm\nZJh+DICvROTJxPf8ThKRRiG2S0REPrkGfxEpFZGlKT/LEr+HpcxzG4C9qjo5wyrqAigB8LCqlgDY\nBWBsWC+AiIj8C3xvHxG5AsAoAP1UtSLD860AvKOqxyYenwngZlUdlj5v4nne2IeIyCe/9/YJdFdP\nERkE4EYAfTIF/kSHtojIehHppKofA+gP4EOndfp9AURE5F+gzF9EVgOoD+DrxKR3VfU/RKQ1gL+o\n6tDEfF0BPAagHoA1AH6mqtsC9ZyIiHJWcLd0JiKi/CuYK3xFZJCIfCQiH4vIzbXdHzci8riIbBGR\npSnTWorITBFZJSJvikjz2uxjNiLSRkRmJy66WyYi1yWmF/xrEJEGIrJARBYn+j4uMb3g+55KROok\nRsC9mngcmf6LyKci8s/E/+C9xLQo9b/GhadR6b+IdEq87x8kfm8Tkev89r8ggr+I1AHwEICzAXQB\ncLGIdK7dXrl6EtbfVGMBzFLV4wHMhvNFb4VgH4AbVLULgNMB/CLxnhf8a0icXzpLVbsD6AbgHBHp\ngQj0Pc0YVD//FaX+xwHEVLW7qvZITItS/9MvPP0IEem/qn6ceN9LAJwMYCeAafDbf1Wt9R8APQHM\nSHk8FjYiqNb75tLvdgCWpjz+CECrxN9HAPiotvvo47W8DGBA1F4DgMYAFgE4NUp9h10QWQogBuDV\nqG0/ANYCOCRtWiT6D6AZgH9lmB6J/qf1+UcA/p5L/wsi8wdwFID1KY83JKZFzeGqugUAVHUzgMNr\nuT+eiEh7WAb9LmzjKfjXkCiZLAawGUCpqi5ERPqe8ABspFzqSbco9V8BlIrIQhG5OjEtKv3PdOFp\nY0Sn/6lGAkheX+Wr/4US/A9UBX82XUSaApgCYIyq7kDNPhfka1DVuFrZpw2AHiLSBRHpu4gMAbBF\nVZcAyDa0uSD7n3CGWtlhMKxk2BsRef9R88LTnbBqQ1T6DwAQkXoAhgN4MTHJV/8LJfh/DqBtyuM2\niWlRsyVxURtE5AgAX9Ryf7ISkbqwwP+0qr6SmByp16B2n6gyAIMQnb6fAWC4iKwB8FcA/UTkaQCb\nI9J/qOqmxO8vYSXDHojO+78BwHpVXZR4PBW2M4hK/5POAfC+qn6VeOyr/4US/BcC6CAi7USkPoCL\nALxay33yQlA9c3sVwBWJv38K4JX0BQrMEwA+VNWJKdMK/jWIyKHJkQyJ+0QNhN0ptuD7DgCqequq\ntlW76v0iALNV9ScAXkME+i8ijRNHjBCRJrC68zJE5/3fAmC9iHRKTOoPYAUi0v8UF8OShyR//a/t\nExYpJy4GAVgFuzX02Nruj4f+TgawEUAFgHUAfgagJYBZidcxE0CL2u5nlv6fAaASwBIAiwF8kPgf\n/KDQXwOAHyb6uwTAUgC3JaYXfN8zvJa+qDrhG4n+w2rmye1mWfLzGpX+J/raFZZ0LgHwEoDmEet/\nYwBfAjg4ZZqv/vMiLyKiIlQoZR8iItqPGPyJiIoQgz8RURFi8CciKkIM/kRERYjBn4ioCDH4ExEV\nIQZ/IqIi9P+75SVnyAS5RwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1112c25c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(res.fx[0:res.total_num_search])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
